{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785093bc-a9bc-4c7c-a431-76b78a3a5afd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Before starting ...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d3e0c-ee7e-49e0-8a7f-49510268baa5",
   "metadata": {},
   "source": [
    "Checking we are using **frugal-notebooks-env** conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecb9e1f2-1013-48b5-9b08-2b8ccb65b3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/avm/Workspace/octo/frugal-ai-challenge/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec74cc-50ae-41e2-9c2e-7096d05d2e26",
   "metadata": {},
   "source": [
    "Checking the python version is 3.9 (compatibility with frugal AI codebase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43c17006-1494-4255-a8b4-58a66fb137f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.6\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51276a7e-dcd6-4121-ad58-912b942acb3e",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122658a4-2acc-4b74-b7d7-206f63ed014c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. **Dataset Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052c0d71-ec7c-4288-b5c3-ff6f62145db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee538d8-fb3a-49da-ad2f-9de1149e774a",
   "metadata": {},
   "source": [
    "**Loading the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d62fb4ee-732d-43d2-87f5-2b701f3a1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/QuotaClimat/frugalaichallenge-text-train/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d891b9-53c0-4f9f-9574-786f7de004d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>subsource</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is clear, compelling evidence that many ...</td>\n",
       "      <td>5_science_unreliable</td>\n",
       "      <td>FLICC</td>\n",
       "      <td>https://huggingface.co/datasets/fzanartu/FLICC...</td>\n",
       "      <td>en</td>\n",
       "      <td>CARDS</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For most of the Holocene (last 10k years), sea...</td>\n",
       "      <td>1_not_happening</td>\n",
       "      <td>FLICC</td>\n",
       "      <td>https://huggingface.co/datasets/fzanartu/FLICC...</td>\n",
       "      <td>en</td>\n",
       "      <td>hamburg_test1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China, which hosts U.N. climate talks next wee...</td>\n",
       "      <td>4_solutions_harmful_unnecessary</td>\n",
       "      <td>FLICC</td>\n",
       "      <td>https://huggingface.co/datasets/fzanartu/FLICC...</td>\n",
       "      <td>en</td>\n",
       "      <td>CARDS</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And the fabricated documents (which Dr. Mann a...</td>\n",
       "      <td>0_not_relevant</td>\n",
       "      <td>FLICC</td>\n",
       "      <td>https://huggingface.co/datasets/fzanartu/FLICC...</td>\n",
       "      <td>en</td>\n",
       "      <td>CARDS</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's going to be 42 here today and the hottest...</td>\n",
       "      <td>1_not_happening</td>\n",
       "      <td>FLICC</td>\n",
       "      <td>https://huggingface.co/datasets/fzanartu/FLICC...</td>\n",
       "      <td>en</td>\n",
       "      <td>hamburg_test3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               quote  \\\n",
       "0  There is clear, compelling evidence that many ...   \n",
       "1  For most of the Holocene (last 10k years), sea...   \n",
       "2  China, which hosts U.N. climate talks next wee...   \n",
       "3  And the fabricated documents (which Dr. Mann a...   \n",
       "4  It's going to be 42 here today and the hottest...   \n",
       "\n",
       "                             label source  \\\n",
       "0             5_science_unreliable  FLICC   \n",
       "1                  1_not_happening  FLICC   \n",
       "2  4_solutions_harmful_unnecessary  FLICC   \n",
       "3                   0_not_relevant  FLICC   \n",
       "4                  1_not_happening  FLICC   \n",
       "\n",
       "                                                 url language      subsource  \\\n",
       "0  https://huggingface.co/datasets/fzanartu/FLICC...       en          CARDS   \n",
       "1  https://huggingface.co/datasets/fzanartu/FLICC...       en  hamburg_test1   \n",
       "2  https://huggingface.co/datasets/fzanartu/FLICC...       en          CARDS   \n",
       "3  https://huggingface.co/datasets/fzanartu/FLICC...       en          CARDS   \n",
       "4  https://huggingface.co/datasets/fzanartu/FLICC...       en  hamburg_test3   \n",
       "\n",
       "     id  \n",
       "0  None  \n",
       "1  None  \n",
       "2  None  \n",
       "3  None  \n",
       "4  None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c21f52-b3fa-4b83-9c1c-936bef845f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is clear, compelling evidence that many ...</td>\n",
       "      <td>5_science_unreliable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For most of the Holocene (last 10k years), sea...</td>\n",
       "      <td>1_not_happening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China, which hosts U.N. climate talks next wee...</td>\n",
       "      <td>4_solutions_harmful_unnecessary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And the fabricated documents (which Dr. Mann a...</td>\n",
       "      <td>0_not_relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's going to be 42 here today and the hottest...</td>\n",
       "      <td>1_not_happening</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               quote  \\\n",
       "0  There is clear, compelling evidence that many ...   \n",
       "1  For most of the Holocene (last 10k years), sea...   \n",
       "2  China, which hosts U.N. climate talks next wee...   \n",
       "3  And the fabricated documents (which Dr. Mann a...   \n",
       "4  It's going to be 42 here today and the hottest...   \n",
       "\n",
       "                             label  \n",
       "0             5_science_unreliable  \n",
       "1                  1_not_happening  \n",
       "2  4_solutions_harmful_unnecessary  \n",
       "3                   0_not_relevant  \n",
       "4                  1_not_happening  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['quote', 'label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44583e43-3572-42fb-98f6-70b27ee54488",
   "metadata": {},
   "source": [
    "**The label have 8 classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80a4ee62-9b16-46a7-8a0f-605a808216fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values:\n",
      "label\n",
      " ['5_science_unreliable' '1_not_happening'\n",
      " '4_solutions_harmful_unnecessary' '0_not_relevant' '6_proponents_biased'\n",
      " '7_fossil_fuels_needed' '2_not_human' '3_not_bad']\n"
     ]
    }
   ],
   "source": [
    "print('unique values:')\n",
    "print('label\\n', df['label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab1fc4-47f5-4088-9de4-2a14a1aaa029",
   "metadata": {},
   "source": [
    "**But we have a bit of unbalanced classes (that we will have to take care of)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf814c75-e591-4843-9c25-3408cbd81e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0_not_relevant                     0.265638\n",
       "1_not_happening                    0.121655\n",
       "2_not_human                        0.115252\n",
       "3_not_bad                          0.063372\n",
       "4_solutions_harmful_unnecessary    0.127073\n",
       "5_science_unreliable               0.131505\n",
       "6_proponents_biased                0.128386\n",
       "7_fossil_fuels_needed              0.047119\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_distribution = df['label'].value_counts().sort_index()\n",
    "df['label'].value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9f8dc00-ee83-4a36-84c2-0d5b5856fdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"920px\"\n",
       "    height=\"420\"\n",
       "    src=\"iframe_figures/figure_9.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.bar(x=class_distribution.index, y=class_distribution.values,\n",
    "             labels={'x': 'Label', 'y': 'Count'})\n",
    "fig.update_layout(width=900, height=400, title=\"Class Distribution\")\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f0302-7fe7-4c3f-a74f-fd9232d9cc65",
   "metadata": {},
   "source": [
    "**We will need to crop some quotes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed6dcf12-b146-4179-add1-c33b60accaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    6091.000000\n",
      "mean      293.528485\n",
      "std       258.330755\n",
      "min        19.000000\n",
      "25%       139.000000\n",
      "50%       228.000000\n",
      "75%       365.000000\n",
      "max      4703.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['text_length'] = df['quote'].str.len()\n",
    "print(df['text_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae22f6ee-1051-4415-9f6c-3e95cfbd79da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"820px\"\n",
       "    height=\"320\"\n",
       "    src=\"iframe_figures/figure_11.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(df, x='text_length', nbins=50)\n",
    "fig.update_layout(width=800, height=300, title=\"Sentence Length Distribution\")\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf6c6999-0b40-4791-bb8f-34bd3011b744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(722.5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = np.percentile(df['text_length'], 95)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95f8773b-d81d-4b63-a65b-7a5d16208a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of quotes above threshold:  305\n"
     ]
    }
   ],
   "source": [
    "long_quotes = df[df['text_length'] > threshold]\n",
    "print('Number of quotes above threshold: ', long_quotes.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2459ec-2937-4b9a-8259-298d1cd53e09",
   "metadata": {},
   "source": [
    "## **2. Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906348d-eb6b-42ec-9072-1ce8e84e11c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Features and target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ebc10cc-75d9-4125-bc82-e792426f0732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6091,), (6091,), pandas.core.series.Series, pandas.core.series.Series)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['quote']\n",
    "y = df['label']\n",
    "X.shape, y.shape, type(X), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cea5b3de-dcd3-4ac7-bc3a-d4703c6581ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    There is clear, compelling evidence that many ...\n",
       "1    For most of the Holocene (last 10k years), sea...\n",
       "2    China, which hosts U.N. climate talks next wee...\n",
       "3    And the fabricated documents (which Dr. Mann a...\n",
       "4    It's going to be 42 here today and the hottest...\n",
       "Name: quote, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c96158bb-101a-4d1e-b620-735312e455f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               5_science_unreliable\n",
       "1                    1_not_happening\n",
       "2    4_solutions_harmful_unnecessary\n",
       "3                     0_not_relevant\n",
       "4                    1_not_happening\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42e598-ca73-48f1-86a2-3feece3cf067",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cc46fce-8393-40c2-81ca-b268a0a3e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import contractions\n",
    "import html\n",
    "import unicodedata\n",
    "from wordsegment import load, segment\n",
    "\n",
    "load()\n",
    "\n",
    "def segment_unseparated(sentence, threshold=20):\n",
    "    return \" \".join(\n",
    "        word if len(word) > threshold else \" \".join(segment(word))\n",
    "        for word in sentence.split()\n",
    "    )\n",
    "\n",
    "def basic_cleaning(sentence:str, threshold:int=15):\n",
    "    sentence = html.unescape(sentence)                        # convert html entities\n",
    "    sentence = re.sub(r'http\\S+|www\\S+', '', sentence)        # remove URLs\n",
    "    sentence = unicodedata.normalize('NFKC', sentence)        # normalize Unicode\n",
    "    sentence = sentence.encode(\"ascii\", \"ignore\").decode()    # remove non ASCII\n",
    "    sentence = contractions.fix(sentence)                     # expand contractions\n",
    "    sentence = sentence.lower()                               # lowercase\n",
    "    sentence = re.sub(r'\\d+', '', sentence)                   # remove digits\n",
    "    punctuation = string.punctuation.replace(\"-\", \"\")         # keep hyphens\n",
    "    translator = str.maketrans('', '', punctuation)\n",
    "    sentence = sentence.translate(translator)                 # remove punctuation\n",
    "    sentence = re.sub(r'\\s-\\s', ' ', sentence)                # removes \" - \" (hyphen surrounded by spaces)\n",
    "    sentence = re.sub(r'\\s-', ' ', sentence)                  # removes leading hyphens\n",
    "    sentence = re.sub(r'-\\s', ' ', sentence)                  # removes trailing hyphens\n",
    "    sentence = segment_unseparated(sentence, threshold=threshold) # separate words that should be separated\n",
    "    sentence = ' '.join(sentence.split()).strip()             # remove whitespace\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4957f925-f5a3-4643-9a1b-84587e196225",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean = X.apply(basic_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8a38797-2f51-42d5-863c-de5064f52038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6091,), pandas.core.series.Series)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean.shape, type(X_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42c3d51c-5619-43df-8f22-268ed13cb28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    there is clear compelling evidence that many o...\n",
       "1    for most of the holocene last k years sea leve...\n",
       "2    china which hosts you n climate talks next wee...\n",
       "3    and the fabricated documents which dr mann app...\n",
       "4    it is going to be here today and the hottest s...\n",
       "Name: quote, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67876840-ea4b-4740-85e4-258bf01bb940",
   "metadata": {},
   "source": [
    "### **Preprocessing**\n",
    "- tokenize\n",
    "- stopwords\n",
    "- lemmatize\n",
    "- rejoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ed645f9-9929-44c9-9375-9b6ef1056c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/avm/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/avm/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/avm/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/avm/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# nltk_path = \"/Users/a.villa.massone/miniconda3/envs/frugal-notebooks-env/nltk_data\" , download_dir=nltk_path\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "def preproc(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tokens = [w for w in tokens if w.lower() not in stop_words]              # remove stop_words\n",
    "    tokens = [WordNetLemmatizer().lemmatize(w, pos = \"v\") for w in tokens]   # lemmatize\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5fa1f81-ba0d-4182-86d4-6b27fee80f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preproc = X_clean.apply(preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1336760-b7d6-4e5a-ab6a-e1a0383ea773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6091,), pandas.core.series.Series)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_preproc.shape, type(X_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d33bc42-424a-4075-9820-97ae35871894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    clear compel evidence many major conclusions i...\n",
       "1    holocene last k years sea level rise rate arou...\n",
       "2    china host n climate talk next week first time...\n",
       "3    fabricate document dr mann apparently still th...\n",
       "4    go today hottest summer record iirc sure globa...\n",
       "Name: quote, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_preproc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d0b0ac-f0f4-4323-b100-ca75d2668892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c82578af-f1dd-4697-b022-9158edddf1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# word_occurrences = (X_vectorized > 0).sum(axis=0)\n",
    "# word_count = dict(zip(vocabulary, np.asarray(word_occurrences).flatten()))\n",
    "\n",
    "# print(f\"\\nVocabulary size: {len(vocabulary)}\")\n",
    "# print()\n",
    "\n",
    "# from nltk.corpus import words\n",
    "# english_vocab = set(words.words())\n",
    "# oov_words = [word for word in vocabulary if word.lower() not in english_vocab]\n",
    "# print(f\"Out-of-vocabulary words: {len(oov_words)}\")\n",
    "# # X_vectorized.head(3)\n",
    "# # print('feature shape:', X_vectorized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0be1d-2a49-4356-9263-e2b2500edea7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Checking quality of preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b0c62f-44c3-47e5-9653-7a1252914200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non alphanum\n",
    "alphanum_error = [word for word in vocabulary if re.search(r\"[^a-zA-Z0-9'-]\", word)]\n",
    "print(\"preprocessing alphanum errors:\", alphanum_error[:20])\n",
    "print('---------------')\n",
    "\n",
    "# case-sensitive duplicates\n",
    "vocab_lower = set(word.lower() for word in vocabulary)\n",
    "if len(vocab_lower) != len(vocabulary):\n",
    "    print(\"Warning: Vocabulary contains case-sensitive duplicates!\")\n",
    "print('---------------')\n",
    "\n",
    "# short words and long words\n",
    "short_words = [word for word in vocabulary if len(word) <= 2]\n",
    "long_words = [word for word in vocabulary if len(word) > 15]\n",
    "\n",
    "print('Longest and shortest words:')\n",
    "print(len(short_words), \"short words (≤2 chars):\\n\", short_words[:20])\n",
    "print(len(long_words), \"long words (>15 chars):\\n\", long_words[:20])\n",
    "print('---------------')\n",
    "\n",
    "# most / least frequent\n",
    "from collections import Counter\n",
    "\n",
    "word_count_counter = Counter(word_count)\n",
    "print(\"Most common words:\\n\", word_count_counter.most_common(10))\n",
    "print(\"Least common words:\\n\", word_count_counter.most_common()[-10:])\n",
    "print('---------------')\n",
    "\n",
    "# out of vocabulary - not english\n",
    "#nltk.download('words', download_dir=nltk_path)\n",
    "from nltk.corpus import words\n",
    "\n",
    "english_vocab = set(words.words())\n",
    "\n",
    "oov_words = [word for word in vocabulary if word.lower() not in english_vocab]\n",
    "print(f\"Out-of-vocabulary words: {len(oov_words)}\")\n",
    "print(\"Sample OOV words:\", oov_words[:20])\n",
    "print('---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45290205-be82-4b46-a4c5-651394552659",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_words = [word for word in vocabulary if len(word) > 15 and len(word) < 20]\n",
    "test_df = pd.DataFrame({\n",
    "    'word' : long_words,\n",
    "    'length': [len(word) for word in long_words],\n",
    "    'separated' : [segment_unseparated(word) for word in long_words]\n",
    "} )\n",
    "# test_df.sort_values(by='length', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df14e9-4e9d-4020-8710-10d0917bf536",
   "metadata": {},
   "source": [
    "**Let's have a look at the most frequent words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5886c7-52d9-4705-a4ea-f6643dc3d290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0585eed4-1214-420d-a41e-26d91aa2860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_20_words = word_count_counter.most_common(40)\n",
    "df_word_freq = pd.DataFrame(top_20_words, columns=['Word', 'Frequency'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(df_word_freq['Word'], df_word_freq['Frequency'])\n",
    "plt.title('Top 40 Most Frequent Words')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "total_words = sum(word_count_counter.values())\n",
    "unique_words = len(vocabulary)\n",
    "average_freq = total_words / unique_words\n",
    "\n",
    "print(f\"\\nTotal words: {total_words}\")\n",
    "print(f\"Unique words: {unique_words}\")\n",
    "print(f\"Average word frequency: {average_freq:.2f}\")\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6a559f-2d82-497c-9a71-11d12556baf1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Encode target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "792c7962-0f77-4da0-a510-7c124c55da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_target(y):\n",
    "    le = LabelEncoder()\n",
    "    y_cat = le.fit_transform(y)\n",
    "    return y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab507e3-8bb6-4ee0-8013-81b254c082bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = encode_target(y)\n",
    "\n",
    "print(le.classes_)\n",
    "print()\n",
    "print('y_cat :', y_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b526949-68d7-4786-8f3d-ead1b0208694",
   "metadata": {},
   "source": [
    "## **3. Baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70217102-fcef-4560-be6d-e0af728bc87d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Feature and target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2845087-3c87-43ba-ad17-f4e93797ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e876a155-d0de-4695-abdb-0e909d151a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2423a36-b8a8-4cb8-b28f-6497bd74f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vectorized.shape, y_cat.shape, type(X_vectorized), type(y_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2e712a-c23d-4558-a3e6-88a87cff9387",
   "metadata": {},
   "source": [
    "**Train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221879fb-c87a-4e58-82a3-46fe4feaa11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y_cat, test_size=0.2, stratify=y_cat, random_state=42)\n",
    "\n",
    "print('types', type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "'Shapes', X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a3ac5-0b85-4f6e-af1e-0af12f6fbd2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Resampling for unbalanced classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cad8c1-8f6e-4924-b286-9bbaa1251061",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(y_train).value_counts(normalize=True))\n",
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4769d2-f400-4428-9986-70063b8e8775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def resampling(X, y):\n",
    "    y = pd.Series(y)\n",
    "\n",
    "    mean_count = int(max(y.value_counts()) / 2)\n",
    "    smote_strategy = {\n",
    "        label: mean_count if count < mean_count else count\n",
    "        for label, count in y.value_counts().items()\n",
    "    }\n",
    "    smote = SMOTE(sampling_strategy=smote_strategy, random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    undersample_strategy = {label: mean_count for label in y.value_counts().keys()}\n",
    "    undersample = RandomUnderSampler(sampling_strategy=undersample_strategy, random_state=42)\n",
    "    X_resampled, y_resampled = undersample.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "X_train, y_train = resampling(X_train, y_train)\n",
    "\n",
    "print(pd.Series(y_train).value_counts(normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bfe11e-7883-4c77-a917-8b4a0ecbacde",
   "metadata": {},
   "source": [
    "**Check the category split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e50196-9793-44c8-8a9b-b0e28b84a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_category_counts = pd.DataFrame(y).value_counts().sort_index()\n",
    "train_category_counts = pd.DataFrame(y_train).value_counts().sort_index()\n",
    "test_category_counts = pd.DataFrame(y_test).value_counts().sort_index()\n",
    "\n",
    "total_proportions = pd.DataFrame(y).value_counts(normalize=True).sort_index().round(2)\n",
    "train_proportions = pd.DataFrame(y_train).value_counts(normalize=True).sort_index().round(2)\n",
    "test_proportions = pd.DataFrame(y_test).value_counts(normalize=True).sort_index().round(2)\n",
    "\n",
    "category_distribution_df = pd.DataFrame({\n",
    "    \"total\": total_category_counts.values,\n",
    "    \"train\": train_category_counts.values,\n",
    "    \"test\": test_category_counts.values,\n",
    "    \"total%\": total_proportions.values,\n",
    "    \"train%\": train_proportions.values,\n",
    "    \"test%\": test_proportions.values\n",
    "}, index=total_category_counts.index)\n",
    "\n",
    "print(category_distribution_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2988ad9-2315-445f-9250-c4517bf16466",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c23ea4-047c-4252-ae07-379b52ef6c37",
   "metadata": {},
   "source": [
    "### **Model : LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d8d8d61-0028-4bbc-a694-2df297ff522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/QuotaClimat/frugalaichallenge-text-train/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56e5c8d5-3c7b-42ad-a556-01ce79d68ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['quote']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4b6c26f-2b05-468e-9fbb-917d4f1c24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = encode_target(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "701aff02-3dee-4dbc-912b-dedf34a6ca42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6091,), (6091,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean = X.apply(basic_cleaning)\n",
    "X_preproc = X_clean.apply(preproc)\n",
    "X_clean.shape, X_preproc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c7841-a57b-4f37-835d-5c512084c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_preproc, y_cat, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86861311-6252-4d9d-b8f1-5a89f4de528e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6091"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from collections import Counter\n",
    "\n",
    "num_words = 15000\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_tokenized = tokenizer.texts_to_sequences(X)\n",
    "# X_train_tokenized = tokenizer.texts_to_sequences(X_train)\n",
    "# X_test_tokenized = tokenizer.texts_to_sequences(X_test)\n",
    "len(X_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5a8dd4c-240a-4118-b260-78cd9e074c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6091, 790)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 750\n",
    "\n",
    "X_pad = pad_sequences(X_tokenized, dtype='float32', padding='post', truncating='post', value=0.0)\n",
    "# X_train_pad = pad_sequences(X_train_tokenized, dtype='float32', padding='post', truncating='post', value=0.0)\n",
    "# X_test_pad = pad_sequences(X_test_tokenized, dtype='float32', padding='post', truncating='post', value=0.0)\n",
    "X_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a02e0b5-7f40-4b2f-8d5a-740409bc88da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences : 6091\n",
      "Original pre-cleaning vocab : 30807\n",
      "Original pre-cleaning max tokens : 4703\n",
      "\n",
      "->Cleaning :\n",
      "\tconvert html entities, \n",
      "\tremove URLs, \n",
      "\tnormalize Unicode, \n",
      "\tremove non ASCII, \n",
      "\texpand contractions, \n",
      "\tlowercase, \n",
      "\tremove digits, \n",
      "\tkeep hyphens, \n",
      "\tseparate stuckup words, \n",
      "\tremove whitespace\n",
      "Sentences : 6091\n",
      "Original post-cleaning vocab : 15507\n",
      "Original post-cleaning max tokens : 4571\n",
      "\n",
      "->Preprocessing :\n",
      "\tremove stop_words, \n",
      "\tlemmatize\n",
      "Sentences : 6091\n",
      "Original post-preproc vocab : 12259\n",
      "Original post-preproc max tokens : 2958\n",
      "\n",
      "->Tokenizing\n",
      "Original vocab : 18587\n",
      "Actual vocab included : 14999\n",
      "Max tokens : 790\n",
      "\n",
      "->Padding\n",
      "Actual vocab included : 15000\n",
      "Max tokens : 790\n"
     ]
    }
   ],
   "source": [
    "print(f'Sentences : {X.shape[0]}')\n",
    "print(f'Original pre-cleaning vocab : {len(set([w for s in X for w in s.split()]))}')\n",
    "print(f'Original pre-cleaning max tokens : {max([len(s) for s in X])}')\n",
    "\n",
    "print('\\n->Cleaning :\\n\\tconvert html entities, \\n\\tremove URLs, \\n\\tnormalize Unicode, \\n\\tremove non ASCII, \\n\\texpand contractions, \\n\\tlowercase, \\n\\tremove digits, \\n\\tkeep hyphens, \\n\\tseparate stuckup words, \\n\\tremove whitespace')\n",
    "print(f'Sentences : {X_clean.shape[0]}')\n",
    "print(f'Original post-cleaning vocab : {len(set([w for s in X_clean for w in s.split()]))}')\n",
    "print(f'Original post-cleaning max tokens : {max([len(s) for s in X_clean])}')\n",
    "\n",
    "print('\\n->Preprocessing :\\n\\tremove stop_words, \\n\\tlemmatize')\n",
    "print(f'Sentences : {X_preproc.shape[0]}')\n",
    "print(f'Original post-preproc vocab : {len(set([w for s in X_preproc for w in s.split()]))}')\n",
    "print(f'Original post-preproc max tokens : {max([len(s) for s in X_preproc])}')\n",
    "\n",
    "print('\\n->Tokenizing')\n",
    "print(f'Original vocab : {len(tokenizer.word_index)}')\n",
    "print(f'Actual vocab included : {len(set([w for s in X_tokenized for w in s]))}')\n",
    "print(f'Max tokens : {max([len(s) for s in X_tokenized])}')\n",
    "\n",
    "print('\\n->Padding')\n",
    "print(f'Actual vocab included : {len(set([w for s in X_pad for w in s]))}')\n",
    "print(f'Max tokens : {max([len(s) for s in X_pad])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "024708e3-f0a5-482d-aa10-5de52138d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter([w for s in X_tokenized for w in s])\n",
    "# dict(sorted(tokenizer.word_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "# dict(sorted(tokenizer.word_docs.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ee440a9-f1e2-481f-87a3-664292a0642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, InputLayer, Embedding\n",
    "\n",
    "def model_init(vocab_size, embedding_dimension):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size + 1, output_dim=embedding_dimension, mask_zero=True))\n",
    "    model.add(LSTM(50, activation='tanh'))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72c0fd16-e555-4a57-8a47-3c779e1bedc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def model_fit(model, X_train, y_train):\n",
    "    \n",
    "    es = EarlyStopping(patience=2, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks = [es],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a73bbc1-ef92-4bdb-b376-3a3a07447f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y_cat, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40d16cce-5dbf-47b3-8471-71f7e04de103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 17:22:38.824887: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = num_words\n",
    "embedding_dimension = 20\n",
    "# max_len = \n",
    "\n",
    "baseline_model = model_init(vocab_size, embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04ef7486-4563-46d5-841a-ed2a65a07e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4872, 790), (1219, 790), (4872,), (1219,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b87d8dec-d8b5-4b64-8cfd-2bebe5c6098a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m baseline_model , history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 7\u001b[0m, in \u001b[0;36mmodel_fit\u001b[0;34m(model, X_train, y_train)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmodel_fit\u001b[39m(model, X_train, y_train):\n\u001b[1;32m      5\u001b[0m     es \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/Workspace/octo/frugal-ai-challenge/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Workspace/octo/frugal-ai-challenge/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py:653\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    649\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    650\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    651\u001b[0m     )\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m--> 653\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    654\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    657\u001b[0m     )\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 8)"
     ]
    }
   ],
   "source": [
    "baseline_model , history = model_fit(baseline_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f419a9-5088-4c05-b411-14c761fe05e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}\")\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2bce14-6970-47db-b1f4-8791e2eadffc",
   "metadata": {},
   "source": [
    "**Baseline : Cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eedc1f-f729-4950-aa4b-b5155e8718eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=41)\n",
    "baseline_accuracy = cross_val_score(baseline_model, X_train, y_train, cv=skf).mean()\n",
    "\n",
    "print(\"Baseline\")\n",
    "print(f\"Cross-validation accuracy on 5 folds: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db5b40-e62d-488d-8bb7-c11723cf7ec4",
   "metadata": {},
   "source": [
    "## 5. **Efficiency metrics : Tracking energy consumption**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6d8401-4225-4818-a141-565cc81fb736",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **During training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f65a22-acef-45c2-b5bb-2b4325062116",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9644bbbc-c6c4-4eea-a10c-8ce0ebc6893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "def monitor_training(model, X_train, y_train):\n",
    "    tracker = EmissionsTracker(log_level=\"error\")\n",
    "    tracker.start()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    training_emissions = tracker.stop()\n",
    "    training_time = tracker.final_emissions_data.duration\n",
    "    training_energy_conso = tracker.final_emissions_data.energy_consumed\n",
    "\n",
    "    train_efficiency_metrics = {\n",
    "        \"total_latency_sec\": training_time,\n",
    "        \"sample_latency_sec\": training_time / X_train.shape[0],\n",
    "        \"total_energy_conso_kWh\": training_energy_conso,\n",
    "        \"sample_energy_conso_kWh\": training_energy_conso / X_train.shape[0],\n",
    "        \"total_emissions_kgCO₂eq\": training_emissions,\n",
    "#        \"tracker_data\": tracker.final_emissions_data\n",
    "    }\n",
    "    train_efficiency_metrics_df = pd.DataFrame.from_dict(train_efficiency_metrics, columns=['metrics'], orient='index')\n",
    "\n",
    "    return model, train_efficiency_metrics_df\n",
    "\n",
    "baseline_model, train_efficiency_metrics_df = monitor_training(baseline_model, X_train, y_train)\n",
    "\n",
    "print(train_efficiency_metrics_df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be0309c-6e50-4cda-bc4a-7ca44fe77ba0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **During inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feae580-d8cf-4b4b-9246-48139579b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb36280-f3be-422f-92dd-35b334e5e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "def monitor_inference(model, X_test):\n",
    "    tracker = EmissionsTracker(log_level=\"error\")\n",
    "    tracker.start()\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    inference_emissions = tracker.stop()\n",
    "    inference_time = tracker.final_emissions_data.duration\n",
    "    inference_energy_conso = tracker.final_emissions_data.energy_consumed\n",
    "\n",
    "    inf_efficiency_metrics = {\n",
    "        \"total_latency_sec\": inference_time,\n",
    "        \"sample_latency_sec\": inference_time / X_test.shape[0],\n",
    "        \"total_energy_conso_kWh\": inference_energy_conso,\n",
    "        \"sample_energy_conso_kWh\": inference_energy_conso / X_test.shape[0],\n",
    "        \"total_emissions_kgCO₂eq\": inference_emissions,\n",
    "#        \"tracker_data\": tracker.final_emissions_data\n",
    "    }\n",
    "    inf_efficiency_metrics_df = pd.DataFrame.from_dict(inf_efficiency_metrics, columns=['metrics'], orient='index')\n",
    "\n",
    "    return y_pred, inf_efficiency_metrics_df\n",
    "\n",
    "y_pred, inf_efficiency_metrics_df = monitor_inference(baseline_model, X_test)\n",
    "\n",
    "print(inf_efficiency_metrics_df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7726c0-22aa-4827-80a7-1578f9babf4c",
   "metadata": {},
   "source": [
    "### **Summary table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe69b8-8571-45b6-81a5-ed7719288618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([train_efficiency_metrics_df, inf_efficiency_metrics_df], axis=1)\n",
    "df_combined.columns = ['training', 'inference']\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c8f857-4a45-494c-9181-879205fd8547",
   "metadata": {},
   "source": [
    "## 4. **Performance metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e7981b-3444-42ef-b998-da0b9fd639d8",
   "metadata": {},
   "source": [
    "**Metrics**  \n",
    "evaluation with :  \n",
    "- accuracy  \n",
    "\n",
    "monitor:  \n",
    "- class_accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f73045-6b05-4d40-bfd6-ede5a67db9e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d25605-0a01-486e-a97e-cacbf10fa71f",
   "metadata": {},
   "source": [
    "**compute metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0fd135-a804-4c71-afb9-76a99422c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe81a14-e10d-4b28-8bf6-7674d7a1e331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score     # tp + tn / all  : maximize correct predictions\n",
    "from sklearn.metrics import precision_score    # tp / (tp + fp) : minimize false positives\n",
    "from sklearn.metrics import recall_score       # tp / (tp + fn) : maximize true positives\n",
    "from sklearn.metrics import f1_score           # harmonic mean of the precision and recall\n",
    "\n",
    "def compute_class_accuracy(y_test, y_pred):\n",
    "    df = pd.DataFrame({'label': y_test, 'correct': y_test == y_pred})\n",
    "    return df.groupby('label')['correct'].mean()\n",
    "\n",
    "def evaluation(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    labels = np.unique(y_pred)\n",
    "    class_accuracy = compute_class_accuracy(y_test, y_pred)\n",
    "    class_precision = precision_score(y_test, y_pred, average=None, labels=labels)\n",
    "    class_recall = recall_score(y_test, y_pred, average=None, labels=labels)\n",
    "    class_f1 = f1_score(y_test, y_pred, average=None, labels=labels)\n",
    "\n",
    "    eval_perf_metrics_df = pd.DataFrame({\n",
    "        \"Category\": labels,\n",
    "        \"Accuracy\": class_accuracy.values,\n",
    "        \"Precision\": class_precision,\n",
    "        \"Recall\": class_recall,\n",
    "        \"F1 Score\": class_f1\n",
    "    })\n",
    "\n",
    "    return accuracy, eval_perf_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93613c6-1c92-4c68-a173-af8410e52aa0",
   "metadata": {},
   "source": [
    "**Plot metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dfec16-f0fe-4819-913a-857aac44f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(accuracy, metrics_df):\n",
    "    '''\n",
    "        metrics_df : df with following format\n",
    "            metrics_df = pd.DataFrame({\n",
    "                \"Category\": labels,\n",
    "                \"Accuracy\": class_accuracy.values,\n",
    "                \"Precision\": class_precision,\n",
    "                \"Recall\": class_recall,\n",
    "                \"F1 Score\": class_f1\n",
    "            })\n",
    "    '''\n",
    "    categories = metrics_df['Category']\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    plt.plot(categories, metrics_df['F1 Score'], marker='o', label='F1 Score')\n",
    "    plt.plot(categories, metrics_df['Precision'], marker='s', label='Precision')\n",
    "    plt.plot(categories, metrics_df['Recall'], marker='^', label='Recall')\n",
    "\n",
    "    plt.axhline(y=accuracy, color='r', linestyle='--', label=f'Accuracy ({accuracy:.2f})')\n",
    "\n",
    "    plt.xlabel(\"Category\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Evaluation Metrics per Category\")\n",
    "    plt.xticks(categories, categories, rotation=45, ha=\"right\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    print(\"Category distribution\")\n",
    "    print(category_distribution_df)\n",
    "    print()\n",
    "    print(\"Category metrics\")\n",
    "    print(metrics_df.round(2))\n",
    "    print()\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d149d643-086a-4397-95b6-8714f8d384a4",
   "metadata": {},
   "source": [
    "**Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab667ce0-cf3e-40f7-94fe-29e38167c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa2ec8a-d186-445f-a877-15c3e4cceba1",
   "metadata": {},
   "source": [
    "### ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54541b-3e42-4330-a097-11137119fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_test_accuracy, eval_perf_metrics_df = evaluation(y_test, y_pred)\n",
    "\n",
    "print('\\nBaseline Test accuracy:', round(baseline_test_accuracy, 3), '\\n')\n",
    "print('Class metrics:\\n')\n",
    "eval_perf_metrics_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd815cf-cc1b-4ff9-99e7-57bce9f34f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(baseline_test_accuracy, eval_perf_metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebba53b2-4c7c-416f-9f1b-1516e8d81008",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87490e56-1349-4194-b2b5-c87483f75a1b",
   "metadata": {},
   "source": [
    "## 6. **Finding the best params with a Randomized Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f340f3-050b-40d0-a93a-d71ebfc2b773",
   "metadata": {},
   "source": [
    "##### **Pipeline and randomized search- Details**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c6fe0e-334c-486e-97fa-3064e6d7e61d",
   "metadata": {},
   "source": [
    "**Preproc functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e13238-9fa7-4c9b-9916-a2f4598c9943",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_X = lambda X, threshold=20: [basic_cleaning(sentence, threshold) for sentence in X]\n",
    "preproc_X = lambda X, threshold=750: [preproc(sentence, threshold) for sentence in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb222529-f436-4a5a-8df0-46067106a0be",
   "metadata": {},
   "source": [
    "**Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191d026f-9cae-4efe-acee-816bc1b03807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from functools import partial\n",
    "\n",
    "resampling_wrapper = lambda X, y=None: resampling(X, y) if y is not None else X\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clean', FunctionTransformer(clean_X)),\n",
    "    ('preproc', FunctionTransformer(preproc_X)),\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('resample', FunctionTransformer(partial(resampling_wrapper))),\n",
    "    ('estimator', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d327458d-8ccf-469b-87f8-13a2b1e25595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "# pipeline.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2bece6-46e0-4771-85c6-559d7e1419ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for param, value in pipeline.get_params().items():\n",
    "#    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e6fa6e-ad8a-4601-91d0-96c8b65ab26d",
   "metadata": {},
   "source": [
    "**Params to evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b76dadb-de9e-4d99-93ed-d3cd2d568797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "param_grid = {\n",
    "    'clean__kw_args': [{\"threshold\": 17}],\n",
    "    'preproc__kw_args': [{\"threshold\": 750}],\n",
    "\n",
    "    'tfidf__max_df' : [0.9],                             # limit high frequency words\n",
    "    'tfidf__max_features': [7500],    # vocabulary size\n",
    "\n",
    "    'estimator__n_estimators': [300],\n",
    "    'estimator__min_samples_split': [5],             # min samples required to split\n",
    "    'estimator__class_weight' : ['balanced'],\n",
    "    'estimator__random_state' : [42]\n",
    "}\n",
    "\n",
    "num_configurations = len(list(product(*param_grid.values())))\n",
    "grid_estimated_time = 3 * num_configurations * train_efficiency_metrics_df[\"metrics\"].loc[\"total_latency_sec\"]\n",
    "random_estimated_time = 3 * 20 * train_efficiency_metrics_df[\"metrics\"].loc[\"total_latency_sec\"]\n",
    "\n",
    "print(f\"Total configurations: {num_configurations}\")\n",
    "print(f'Estimated time to complete with grid search : {round(grid_estimated_time, 2)} sec')\n",
    "print(f'Estimated time to complete with randomized search : {round(random_estimated_time, 2)} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d40b1-fead-4998-8e48-646054db1efa",
   "metadata": {},
   "source": [
    "**Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67315ab6-9f62-4a01-b987-d99eff206070",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode labels\n",
    "y = df['label']\n",
    "le = LabelEncoder()\n",
    "y_cat = le.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X = df['quote']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_cat, test_size=0.2, stratify=y_cat, random_state=42\n",
    ")\n",
    "\n",
    "# Run grid search\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "print('Best parameters:')\n",
    "print(search.best_params_)\n",
    "print(f\"\\nBest accuracy: {round(search.best_score_, 3)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b624e7a9-a557-4e77-bec9-e7259a3f399e",
   "metadata": {},
   "source": [
    "##### **Best params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e9769f-138d-44cd-9fbb-73f58975c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters:')\n",
    "[print(f'{k}:{v}') for (k, v) in search.best_params_.items()]\n",
    "print(f\"\\nBest accuracy: {round(search.best_score_, 3)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e43c04-6824-421b-9f88-061ce175c752",
   "metadata": {},
   "source": [
    "## 7. **Evaluating the best model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fb3bf9-14d7-4cd3-aa7d-227b42b91cb1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Prepare data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8dcd1a-bc5c-420b-b0fe-160ebec82921",
   "metadata": {},
   "source": [
    "**Feature and target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d161896-ab90-460b-abcd-5ccf1bef2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['quote']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9976967-3b3b-4f29-868c-07ee4c45492d",
   "metadata": {},
   "source": [
    "**Encode labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf927086-b6eb-43f7-9268-c736a9aa9db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_cat = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29633940-34b0-4dfa-9fca-04a7684abc33",
   "metadata": {},
   "source": [
    "**Clean, preproc, vectorize X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9bc7c-ecc4-49d8-a730-50d3daf07827",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean = X.apply(basic_cleaning)\n",
    "X_preproc = X_clean.apply(preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587ff90-e3ca-4cc7-ac0e-9fa6661312fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d3fcca-10d1-43e2-9fe5-bd92bdd97a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_params = {k.replace(\"tfidf__\", \"\"): v for k, v in search.best_params_.items() if k.startswith(\"tfidf__\")}\n",
    "#tfidf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db42c209-f455-4af1-a6dd-e2199620e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(**tfidf_params)\n",
    "\n",
    "X_vectorized = pd.DataFrame(\n",
    "    vectorizer.fit_transform(X_preproc).toarray(),\n",
    "    columns=vectorizer.get_feature_names_out(),\n",
    "    index=X_preproc.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47bf5e4-a318-4ee2-9798-401eed57b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"TfidfVectorizer Parameters:\", vectorizer.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e8193e-1e8d-4a98-99f4-386c2eff5a6d",
   "metadata": {},
   "source": [
    "**Split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c0fcb3-b270-4ec6-a6de-5e0129d34f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vectorized, y_cat, test_size=0.2, stratify=y_cat, random_state=42\n",
    ")\n",
    "print('types', type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "'Shapes', X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bf008a-e43c-49c0-b0e5-63a8d3636992",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Monitor best model energy consumption during training and inference - details**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b9042c-cb53-4988-a723-4e902ef70c65",
   "metadata": {},
   "source": [
    "**Monitor best model during training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc5a62-4938-4a41-9c88-8ad36933ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d6e541-692a-43ae-acba-e275e79ae941",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_params = {k.replace(\"estimator__\", \"\"): v for k, v in search.best_params_.items() if k.startswith(\"estimator__\")}\n",
    "#estimator_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523dce2f-e93c-460f-a8c5-2c19596d7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestClassifier(**estimator_params)\n",
    "#print(\"RandomForestClassifier Parameters:\", best_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb7876-071b-487f-b8b7-b0879019c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_model_train_metrics_df = monitor_training(best_model, X_train, y_train)\n",
    "print(best_model_train_metrics_df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d58fa-d1e6-4add-9165-67138daf633a",
   "metadata": {},
   "source": [
    "**Monitor best model during inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d3970b-b289-473c-8700-b368e5f54792",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, best_model_inf_metrics_df = monitor_inference(best_model, X_test)\n",
    "\n",
    "print(best_model_inf_metrics_df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee821ca-83f1-4c5b-9b71-05fb1bca8079",
   "metadata": {},
   "source": [
    "##### **Monitor best model energy consumption during training and inference - summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef23bf-4a07-4f51-ac2a-2b7e3a603ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([train_efficiency_metrics_df, inf_efficiency_metrics_df], axis=1)\n",
    "df_combined.columns = ['training', 'inference']\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a26d3a1-3a06-4fef-b5e5-aca507133064",
   "metadata": {},
   "source": [
    "##### **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd9d93-b9ea-4815-967f-941d62a687c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_test_accuracy, best_model_eval_perf_metrics_df = evaluation(y_test, y_pred)\n",
    "\n",
    "print('\\nAccuracy:', round(best_model_test_accuracy, 3), '\\n')\n",
    "print('Class metrics:')\n",
    "best_model_eval_perf_metrics_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb40093b-382b-44b2-bd5a-ed8a7d303f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(best_model_test_accuracy, best_model_eval_perf_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36e748-51ae-46fa-b4dd-d7f88ffebca4",
   "metadata": {},
   "source": [
    "**Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a5e5e5-3118-44ca-ad05-a7cdd653f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f7e112-ebea-4dac-aede-3a67f08f09e7",
   "metadata": {},
   "source": [
    "## 8. **Save metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a645dc-89f7-4d40-a224-ed5081e555ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ba340-52d3-47ec-b1be-1a604c9e2cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "note = \"Baseline ML, improved preproc, param search\"\n",
    "model_name = 'RandomForestClassifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e39b89-a95e-4f47-8aa6-280fe0cd1259",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = (\n",
    "    \"metrics/\"\n",
    "    f\"{'_'.join(model_name.split('/'))}\"\n",
    "    f\"_accuracy_{int(best_model_test_accuracy * 100)}\"\n",
    "    f\"_dt_{timestamp.replace(':', '').replace('-', '')}\"\n",
    "    \".json\"\n",
    ")\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add0cead-3a52-4763-975d-c9c80212c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"metrics\", exist_ok=True)\n",
    "\n",
    "data = {\n",
    "    \"model_name\": model_name,\n",
    "    \"timestamp\": timestamp,\n",
    "    \"note\": note,\n",
    "\n",
    "    \"baseline_test_accuracy\": baseline_test_accuracy,\n",
    "    \"best_model_test_accuracy\": best_model_test_accuracy,\n",
    "\n",
    "    \"total_training_latency_sec\": train_efficiency_metrics_df['metrics'].loc['total_latency_sec'],\n",
    "    \"total_training_energy_conso_kWh\": train_efficiency_metrics_df['metrics'].loc['total_energy_conso_kWh'],\n",
    "\n",
    "    \"total_inference_latency_sec\": inf_efficiency_metrics_df['metrics'].loc['total_latency_sec'],\n",
    "    \"total_inference_energy_conso_kWh\": inf_efficiency_metrics_df['metrics'].loc['total_energy_conso_kWh'],\n",
    "\n",
    "    \"sample_inference_latency_sec\": inf_efficiency_metrics_df['metrics'].loc['sample_latency_sec'],\n",
    "    \"sample_inference_energy_conso_kWh\": inf_efficiency_metrics_df['metrics'].loc['sample_energy_conso_kWh'],\n",
    "\n",
    "    \"train_size\" : y_train.shape[0],\n",
    "    \"test_size\" :  y_test.shape[0],\n",
    "    \"class_performance_metrics\": eval_perf_metrics_df.to_dict(orient=\"records\"),\n",
    "    \"search_best_params\" : search.best_params_,\n",
    "    \"training_efficiency_metrics\": train_efficiency_metrics_df.to_dict(orient=\"records\"),\n",
    "    \"inference_efficiency_metrics\": inf_efficiency_metrics_df.to_dict(orient=\"records\")\n",
    "}\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff80c55-58d5-456b-88f4-47a71ca17d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(filename, \"w\") as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "print(f\"Metrics saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37617f10-0430-449b-a08f-be2c32e594d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
