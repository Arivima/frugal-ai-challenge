{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a5dade-b369-4b4a-aa62-c4903fc566eb",
   "metadata": {},
   "source": [
    "##### **Before starting ...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d3e0c-ee7e-49e0-8a7f-49510268baa5",
   "metadata": {},
   "source": [
    "Checking we are using frugal-notebooks-env conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecb9e1f2-1013-48b5-9b08-2b8ccb65b3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/a.villa.massone/miniconda3/envs/frugal-notebooks-env/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec74cc-50ae-41e2-9c2e-7096d05d2e26",
   "metadata": {},
   "source": [
    "Checking the python version is 3.9 (compatibility with frugal AI codebase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43c17006-1494-4255-a8b4-58a66fb137f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.21\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19951a5b-cd29-4154-8ca5-12e41c8dec88",
   "metadata": {},
   "source": [
    "Checking the pytorch version is > 1.12+ (compatibility with MPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "020ae9c3-5d4d-4568-ade5-6e3e3015394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0476d9-94e8-40a8-8cf4-bdf7f70a3301",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d2eb284-d832-4b5c-b473-3df42a05af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51276a7e-dcd6-4121-ad58-912b942acb3e",
   "metadata": {},
   "source": [
    "# Fine tuning LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7627d2c5-397f-40e1-bf74-f1181cc149bf",
   "metadata": {},
   "source": [
    "## 2. **Baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee538d8-fb3a-49da-ad2f-9de1149e774a",
   "metadata": {},
   "source": [
    "### **dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d62fb4ee-732d-43d2-87f5-2b701f3a1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/QuotaClimat/frugalaichallenge-text-train/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26c99f47-9074-407c-a5d0-f551fb1e5398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9f0654-c0b6-4ca8-b513-662ef0fe05f7",
   "metadata": {},
   "source": [
    "### **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "412e4c5f-e099-4102-b07f-f2fd17391a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = \"mistral\"\n",
    "\n",
    "MODEL_NAMES = {\n",
    "    \"mistral\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    \"phi2\": \"microsoft/phi-2\",\n",
    "    \"qwen\": \"Qwen/Qwen2.5-0.5B\"\n",
    "}\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # Suppress multiprocessing warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "674f7fd6-0b9f-4d52-969f-65026841129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "def load_model(model_name):\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    ).eval()\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e460d7-5792-44b8-9dc0-b3022f3601de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a6a46c69fa4ed2a7baff76d850becf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.79 s, sys: 7.18 s, total: 16 s\n",
      "Wall time: 26.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = MODEL_NAMES[selected_model]\n",
    "tokenizer, model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b02e64cd-e6e2-4057-bee8-91572d516f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mmodels--Qwen--Qwen2.5-0.5B\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mmodels--Qwen--Qwen2.5-7B\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mmodels--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mmodels--mistralai--Mistral-7B-Instruct-v0.1\u001b[m\u001b[m\n",
      "version.txt\n"
     ]
    }
   ],
   "source": [
    "!ls ~/.cache/huggingface/hub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a77072b-6dd8-4c7a-9435-1c80ef8c44c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13G\t/Users/a.villa.massone/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1\n"
     ]
    }
   ],
   "source": [
    "!du -sh ~/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a532f7-85d9-4b28-abb0-9372b54d3f37",
   "metadata": {},
   "source": [
    "### **Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58b773db-1e05-4730-80b0-d32ce6218d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(text):\n",
    "    return f\"\"\"\n",
    "<instruction>\n",
    "Classify the following statement into one of these 8 categories:\n",
    "Respond STRICTLY with only the corresponding number.\n",
    "</instruction>\n",
    "\n",
    "<categories>\n",
    "0 - Not relevant: No climate-related claims or doesn't fit other categories\n",
    "1 - Denial: Claims climate change is not happening\n",
    "2 - Attribution denial: Claims human activity is not causing climate change\n",
    "3 - Impact minimization: Claims climate change impacts are minimal or beneficial\n",
    "4 - Solution opposition: Claims solutions to climate change are harmful\n",
    "5 - Science skepticism: Challenges climate science validity or methods\n",
    "6 - Actor criticism: Attacks credibility of climate scientists or activists\n",
    "7 - Fossil fuel promotion: Asserts importance of fossil fuels\n",
    "</categories>\n",
    "\n",
    "<statement>\n",
    "Statement: \"{text}\"\n",
    "</statement>\n",
    "\n",
    "Category number:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b0c5c87-45af-49f1-b81b-d01394be6d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(text):\n",
    "    return f\"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "Classify the following statement into one of these 8 categories:\n",
    "Respond STRICTLY with only the corresponding number.\n",
    "<</SYS>>\n",
    "\n",
    "<categories>\n",
    "0 - Not relevant: No climate-related claims or doesn't fit other categories\n",
    "1 - Denial: Claims climate change is not happening\n",
    "2 - Attribution denial: Claims human activity is not causing climate change\n",
    "3 - Impact minimization: Claims climate change impacts are minimal or beneficial\n",
    "4 - Solution opposition: Claims solutions to climate change are harmful\n",
    "5 - Science skepticism: Challenges climate science validity or methods\n",
    "6 - Actor criticism: Attacks credibility of climate scientists or activists\n",
    "7 - Fossil fuel promotion: Asserts importance of fossil fuels\n",
    "</categories>\n",
    "\n",
    "<statement>\n",
    "Statement: \"{text}\"\n",
    "</statement>\n",
    "[/INST]\n",
    "\n",
    "Category number:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c11e77a-e29d-432f-8985-6b315b485b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_LABELS = [\n",
    "    \"0_not_relevant\",\n",
    "    \"1_not_happening\",\n",
    "    \"2_not_human\",\n",
    "    \"3_not_bad\",\n",
    "    \"4_solutions_harmful_unnecessary\",\n",
    "    \"5_science_unreliable\",\n",
    "    \"6_proponents_biased\",\n",
    "    \"7_fossil_fuels_needed\"\n",
    "]\n",
    "\n",
    "def get_label_id(row):\n",
    "    return row['label'].split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba7a3427-80dd-4585-9299-f97ba28853bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example': '\\n<s>[INST] <<SYS>>\\nClassify the following statement into one of these 8 categories:\\nRespond STRICTLY with only the corresponding number.\\n<</SYS>>\\n\\n<categories>\\n0 - Not relevant: No climate-related claims or doesn\\'t fit other categories\\n1 - Denial: Claims climate change is not happening\\n2 - Attribution denial: Claims human activity is not causing climate change\\n3 - Impact minimization: Claims climate change impacts are minimal or beneficial\\n4 - Solution opposition: Claims solutions to climate change are harmful\\n5 - Science skepticism: Challenges climate science validity or methods\\n6 - Actor criticism: Attacks credibility of climate scientists or activists\\n7 - Fossil fuel promotion: Asserts importance of fossil fuels\\n</categories>\\n\\n<statement>\\nStatement: \"There is clear, compelling evidence that many of the major conclusions of the IPCC, your new religions constantly-changing Holy Book, are based on evidence that has been fabricated. The hockey stick graph that purported to abolish the mediaeval warm period is just one example.\"\\n</statement>\\n[/INST]\\n\\nCategory number:\\n<category>5</category>'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_example(row):\n",
    "    prompt = create_prompt(row['quote'])\n",
    "    category = row['label'].split('_')[0]\n",
    "    return {\"example\": prompt + \"\\n<category>\" + category + \"</category>\"}\n",
    "\n",
    "format_example(df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42af27f6-7299-4b08-bc6f-91462208bc29",
   "metadata": {},
   "source": [
    "### **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f99a6c-8902-4b2c-a3f8-d92c4e85514c",
   "metadata": {},
   "source": [
    "**Train sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc93b598-34e0-430d-abad-623525130c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train set size (3897, 7)\n",
      "Original val set size (975, 7)\n",
      "Original test set size (1219, 7)\n",
      "Sample train set size (50, 7)\n",
      "Sample val set size (50, 7)\n",
      "6424    {'example': '\n",
      "<s>[INST] <<SYS>>\n",
      "Classify the f...\n",
      "dtype: object\n",
      "2987    {'example': '\n",
      "<s>[INST] <<SYS>>\n",
      "Classify the f...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "N_SAMPLES = 50\n",
    "\n",
    "print('Original train set size', train_df.shape)\n",
    "print('Original val set size', val_df.shape)\n",
    "print('Original test set size', test_df.shape)\n",
    "\n",
    "df_sampled_train = train_df.sample(N_SAMPLES, random_state=42)\n",
    "df_sampled_val = val_df.sample(N_SAMPLES, random_state=42)\n",
    "print('Sample train set size', df_sampled_train.shape)\n",
    "print('Sample val set size', df_sampled_train.shape)\n",
    "\n",
    "train_formatted = df_sampled_train.apply(format_example, axis=1)\n",
    "val_formatted = df_sampled_val.apply(format_example, axis=1)\n",
    "\n",
    "print(train_formatted[:1])\n",
    "print(val_formatted[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50f04614-5346-42a6-a607-0376a7a51203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled_train.apply(format_example, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc45e2d3-e9e2-4793-814c-0ead282fc17e",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "86ad72ea-4b29-4f1c-8f74-89084408d781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_dir': './tmp',\n",
       " 'overwrite_output_dir': False,\n",
       " 'do_train': False,\n",
       " 'do_eval': False,\n",
       " 'do_predict': False,\n",
       " 'eval_strategy': <IntervalStrategy.NO: 'no'>,\n",
       " 'prediction_loss_only': False,\n",
       " 'per_device_train_batch_size': 8,\n",
       " 'per_device_eval_batch_size': 8,\n",
       " 'per_gpu_train_batch_size': None,\n",
       " 'per_gpu_eval_batch_size': None,\n",
       " 'gradient_accumulation_steps': 1,\n",
       " 'eval_accumulation_steps': None,\n",
       " 'eval_delay': 0,\n",
       " 'torch_empty_cache_steps': None,\n",
       " 'learning_rate': 2e-05,\n",
       " 'weight_decay': 0.0,\n",
       " 'adam_beta1': 0.9,\n",
       " 'adam_beta2': 0.999,\n",
       " 'adam_epsilon': 1e-08,\n",
       " 'max_grad_norm': 1.0,\n",
       " 'num_train_epochs': 3.0,\n",
       " 'max_steps': -1,\n",
       " 'lr_scheduler_type': <SchedulerType.LINEAR: 'linear'>,\n",
       " 'lr_scheduler_kwargs': {},\n",
       " 'warmup_ratio': 0.0,\n",
       " 'warmup_steps': 0,\n",
       " 'log_level': 'passive',\n",
       " 'log_level_replica': 'warning',\n",
       " 'log_on_each_node': True,\n",
       " 'logging_dir': './tmp/runs/Feb03_11-32-38_AMAFHP9MXRXX1',\n",
       " 'logging_strategy': <IntervalStrategy.STEPS: 'steps'>,\n",
       " 'logging_first_step': False,\n",
       " 'logging_steps': 500,\n",
       " 'logging_nan_inf_filter': True,\n",
       " 'save_strategy': <SaveStrategy.STEPS: 'steps'>,\n",
       " 'save_steps': 500,\n",
       " 'save_total_limit': None,\n",
       " 'save_safetensors': True,\n",
       " 'save_on_each_node': False,\n",
       " 'save_only_model': False,\n",
       " 'restore_callback_states_from_checkpoint': False,\n",
       " 'no_cuda': False,\n",
       " 'use_cpu': False,\n",
       " 'use_mps_device': False,\n",
       " 'seed': 42,\n",
       " 'data_seed': None,\n",
       " 'jit_mode_eval': False,\n",
       " 'use_ipex': False,\n",
       " 'bf16': False,\n",
       " 'fp16': False,\n",
       " 'fp16_opt_level': 'O1',\n",
       " 'half_precision_backend': 'auto',\n",
       " 'bf16_full_eval': False,\n",
       " 'fp16_full_eval': False,\n",
       " 'tf32': None,\n",
       " 'local_rank': 0,\n",
       " 'ddp_backend': None,\n",
       " 'tpu_num_cores': None,\n",
       " 'tpu_metrics_debug': False,\n",
       " 'debug': [],\n",
       " 'dataloader_drop_last': False,\n",
       " 'eval_steps': None,\n",
       " 'dataloader_num_workers': 0,\n",
       " 'dataloader_prefetch_factor': None,\n",
       " 'past_index': -1,\n",
       " 'run_name': './tmp',\n",
       " 'disable_tqdm': False,\n",
       " 'remove_unused_columns': True,\n",
       " 'label_names': None,\n",
       " 'load_best_model_at_end': False,\n",
       " 'metric_for_best_model': None,\n",
       " 'greater_is_better': None,\n",
       " 'ignore_data_skip': False,\n",
       " 'fsdp': [],\n",
       " 'fsdp_min_num_params': 0,\n",
       " 'fsdp_config': {'min_num_params': 0,\n",
       "  'xla': False,\n",
       "  'xla_fsdp_v2': False,\n",
       "  'xla_fsdp_grad_ckpt': False},\n",
       " 'fsdp_transformer_layer_cls_to_wrap': None,\n",
       " 'accelerator_config': AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None, use_configured_state=False),\n",
       " 'deepspeed': None,\n",
       " 'label_smoothing_factor': 0.0,\n",
       " 'optim': <OptimizerNames.ADAMW_TORCH: 'adamw_torch'>,\n",
       " 'optim_args': None,\n",
       " 'adafactor': False,\n",
       " 'group_by_length': False,\n",
       " 'length_column_name': 'length',\n",
       " 'report_to': ['codecarbon'],\n",
       " 'ddp_find_unused_parameters': None,\n",
       " 'ddp_bucket_cap_mb': None,\n",
       " 'ddp_broadcast_buffers': None,\n",
       " 'dataloader_pin_memory': True,\n",
       " 'dataloader_persistent_workers': False,\n",
       " 'skip_memory_metrics': True,\n",
       " 'use_legacy_prediction_loop': False,\n",
       " 'push_to_hub': False,\n",
       " 'resume_from_checkpoint': None,\n",
       " 'hub_model_id': None,\n",
       " 'hub_strategy': <HubStrategy.EVERY_SAVE: 'every_save'>,\n",
       " 'hub_token': None,\n",
       " 'hub_private_repo': None,\n",
       " 'hub_always_push': False,\n",
       " 'gradient_checkpointing': False,\n",
       " 'gradient_checkpointing_kwargs': None,\n",
       " 'include_inputs_for_metrics': False,\n",
       " 'include_for_metrics': [],\n",
       " 'eval_do_concat_batches': True,\n",
       " 'fp16_backend': 'auto',\n",
       " 'evaluation_strategy': None,\n",
       " 'push_to_hub_model_id': None,\n",
       " 'push_to_hub_organization': None,\n",
       " 'push_to_hub_token': None,\n",
       " 'mp_parameters': '',\n",
       " 'auto_find_batch_size': False,\n",
       " 'full_determinism': False,\n",
       " 'torchdynamo': None,\n",
       " 'ray_scope': 'last',\n",
       " 'ddp_timeout': 1800,\n",
       " 'torch_compile': False,\n",
       " 'torch_compile_backend': None,\n",
       " 'torch_compile_mode': None,\n",
       " 'dispatch_batches': None,\n",
       " 'split_batches': None,\n",
       " 'include_tokens_per_second': False,\n",
       " 'include_num_input_tokens_seen': False,\n",
       " 'neftune_noise_alpha': None,\n",
       " 'optim_target_modules': None,\n",
       " 'batch_eval_metrics': False,\n",
       " 'eval_on_start': False,\n",
       " 'use_liger_kernel': False,\n",
       " 'eval_use_gather_object': False,\n",
       " 'average_tokens_across_devices': False,\n",
       " 'dataset_text_field': 'example',\n",
       " 'packing': False,\n",
       " 'max_seq_length': None,\n",
       " 'dataset_num_proc': None,\n",
       " 'dataset_batch_size': 1000,\n",
       " 'model_init_kwargs': None,\n",
       " 'dataset_kwargs': None,\n",
       " 'eval_packing': None,\n",
       " 'num_of_sequences': 1024,\n",
       " 'chars_per_token': 3.6,\n",
       " 'use_liger': False,\n",
       " 'distributed_state': Distributed environment: NO\n",
       " Num processes: 1\n",
       " Process index: 0\n",
       " Local process index: 0\n",
       " Device: mps,\n",
       " '_n_gpu': 1,\n",
       " '__cached__setup_devices': device(type='mps'),\n",
       " 'deepspeed_plugin': None}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trl import SFTConfig\n",
    "\n",
    "use_fp16 = torch.cuda.is_available()  # Disable for MPS\n",
    "use_bf16 = torch.cuda.is_bf16_supported() and not torch.backends.mps.is_available()\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"./tmp\",\n",
    "    dataset_text_field=\"example\",\n",
    ")\n",
    "training_args.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1601891c-e865-4df2-9f6a-8adfc1ec3792",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'column_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d9/9y41j_px1zz0j3v_hsz37l4m0000gn/T/ipykernel_92617/3917446999.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFTTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m trainer = SFTTrainer(\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mminimum_action\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTIFY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTIFY_ALWAYS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;31m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics, peft_config, formatting_func)\u001b[0m\n\u001b[1;32m    293\u001b[0m                         \u001b[0mremove_unused_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_unused_columns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                         \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                     )\n\u001b[1;32m    296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_multiple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                     \u001b[0meval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_eval_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"singleton\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprocessing_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_side\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mprocessing_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_side\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"right\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             warnings.warn(\n",
      "\u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dataset, processing_class, packing, dataset_text_field, max_seq_length, formatting_func, num_of_sequences, chars_per_token, remove_unused_columns, append_concat_token, add_special_tokens, skip_prepare_dataset)\u001b[0m\n\u001b[1;32m    376\u001b[0m         ) and not isinstance(dataset, datasets.IterableDataset):\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpacking\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             return self._prepare_non_packed_dataloader(\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0mprocessing_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mdataset_text_field\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/trl/trainer/sft_trainer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, processing_class, dataset, dataset_text_field, max_seq_length, formatting_func, add_special_tokens, remove_unused_columns)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0msignature_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# None for IterableDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m             \u001b[0mextra_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0mextra_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'column_names'"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_formatted,\n",
    "    eval_dataset=val_formatted,\n",
    "    #compute_metrics = # accuracy, do we need preprocess_logits_for_metrics ?\n",
    ")\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bce894a8-cc64-48a9-a429-843485d13f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d9/9y41j_px1zz0j3v_hsz37l4m0000gn/T/ipykernel_92617/1145065633.py:5: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'dataset_text_field'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SFTTrainer, SFTConfig\n\u001b[1;32m      3\u001b[0m training_args \u001b[38;5;241m=\u001b[39m SFTConfig(output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mSFTTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_formatted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_formatted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_text_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Start Training\u001b[39;00m\n\u001b[1;32m     14\u001b[0m fine_tuned_model \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/transformers/utils/deprecation.py:165\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'dataset_text_field'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Start Training\n",
    "fine_tuned_model = trainer.train()\n",
    "\n",
    "# Save Model\n",
    "trainer.save_model(\"./models/fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a429db1-c7d6-4a5b-8cc1-ddef384f3542",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = PeftModel.from_pretrained(model, \"fine_tuned_model\")\n",
    "fine_tuned_model = fine_tuned_model.merge_and_unload()  # For LoRA models\n",
    "\n",
    "# Inference\n",
    "y_pred, _ = batch_inference(model, tokenizer, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f45498cd-b64f-4620-b866-9adb763f328f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 35\u001b[0m\n\u001b[1;32m     18\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     19\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     eval_accumulation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Initialize Trainer\u001b[39;00m\n\u001b[1;32m     32\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SFTTrainer(\n\u001b[1;32m     33\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     34\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m---> 35\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_example\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     36\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtest_df\u001b[38;5;241m.\u001b[39mmap(format_example),\n\u001b[1;32m     37\u001b[0m     dataset_text_field\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m     39\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     40\u001b[0m     peft_config\u001b[38;5;241m=\u001b[39mpeft_config,\n\u001b[1;32m     41\u001b[0m     packing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Start Training\u001b[39;00m\n\u001b[1;32m     45\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/pandas/core/frame.py:10468\u001b[0m, in \u001b[0;36mDataFrame.map\u001b[0;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[1;32m  10465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[1;32m  10466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39m_map_values(func, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m> 10468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/pandas/core/frame.py:10466\u001b[0m, in \u001b[0;36mDataFrame.map.<locals>.infer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m  10465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[0;32m> 10466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m, in \u001b[0;36mformat_example\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_example\u001b[39m(row):\n\u001b[0;32m----> 2\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m create_prompt(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquote\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      3\u001b[0m     category \u001b[38;5;241m=\u001b[39m get_label_id(row)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m<category>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m category \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</category>\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from peft import LoraConfig\n",
    "\n",
    "\"\"\"\n",
    "# PEFT Configuration\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "#    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "max_seq_lenght = min(tokenizer.model_max_length, 1024)\n",
    "\n",
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=not torch.backends.mps.is_available(),\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_steps=20,\n",
    "    eval_accumulation_steps=5\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_df.map(format_example),\n",
    "    eval_dataset=test_df.map(format_example),\n",
    "    dataset_text_field=\"example\",\n",
    "    max_seq_length=512,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=peft_config,\n",
    "    packing=False\n",
    ")\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051fb616-f90e-46f8-928c-2c415a895cc5",
   "metadata": {},
   "source": [
    "**Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f292a41f-4e44-40e0-8f96-25eef5f80483",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load fine-tuned model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m fine_tuned_model \u001b[38;5;241m=\u001b[39m PeftModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfine_tuned_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/peft/__init__.py:22\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# module, but to preserve other warnings. So, don't check this module at all.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.14.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     AutoPeftModel,\n\u001b[1;32m     24\u001b[0m     AutoPeftModelForCausalLM,\n\u001b[1;32m     25\u001b[0m     AutoPeftModelForSequenceClassification,\n\u001b[1;32m     26\u001b[0m     AutoPeftModelForSeq2SeqLM,\n\u001b[1;32m     27\u001b[0m     AutoPeftModelForTokenClassification,\n\u001b[1;32m     28\u001b[0m     AutoPeftModelForQuestionAnswering,\n\u001b[1;32m     29\u001b[0m     AutoPeftModelForFeatureExtraction,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     MODEL_TYPE_TO_PEFT_MODEL_MAPPING,\n\u001b[1;32m     33\u001b[0m     PEFT_TYPE_TO_CONFIG_MAPPING,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     inject_adapter_in_model,\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftMixedModel\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/peft/auto.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     AutoModel,\n\u001b[1;32m     23\u001b[0m     AutoModelForCausalLM,\n\u001b[1;32m     24\u001b[0m     AutoModelForQuestionAnswering,\n\u001b[1;32m     25\u001b[0m     AutoModelForSeq2SeqLM,\n\u001b[1;32m     26\u001b[0m     AutoModelForSequenceClassification,\n\u001b[1;32m     27\u001b[0m     AutoModelForTokenClassification,\n\u001b[1;32m     28\u001b[0m     AutoTokenizer,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftConfig\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/transformers/__init__.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     29\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     logging,\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/transformers/dependency_versions_check.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[1;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/transformers/utils/__init__.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbone_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackboneConfigMixin, BackboneMixin\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_template_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocstringParsingException, TypeHintParsingException, get_json_schema\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     add_code_sample_docstrings,\n\u001b[1;32m     31\u001b[0m     add_end_docstrings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     replace_return_docstrings,\n\u001b[1;32m     36\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/transformers/utils/chat_template_utils.py:40\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[1;32m     43\u001b[0m BASIC_TYPES \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, Any, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Extracts the initial segment of the docstring, containing the function description\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/torch/__init__.py:404\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;66;03m# Easy way.  You want this most of the time, because it will prevent\u001b[39;00m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;66;03m# C++ symbols from libtorch clobbering C++ symbols from other\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# See Note [Global dependencies]\u001b[39;00m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[0;32m--> 404\u001b[0m         \u001b[43m_load_global_deps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSymInt\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/site-packages/torch/__init__.py:318\u001b[0m, in \u001b[0;36m_load_global_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    315\u001b[0m global_deps_lib_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(here), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlib\u001b[39m\u001b[38;5;124m\"\u001b[39m, lib_name)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglobal_deps_lib_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRTLD_GLOBAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# Workaround slim-wheel CUDA dependency bugs in cusparse and cudnn by preloading nvjitlink\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# and nvrtc. In CUDA-12.4+ cusparse depends on nvjitlink, but does not have rpath when\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;66;03m# shipped as wheel, which results in OS picking wrong/older version of nvjitlink library\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# if `LD_LIBRARY_PATH` is defined, see https://github.com/pytorch/pytorch/issues/138460\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# Similar issue exist in cudnn that dynamically loads nvrtc, unaware of its relative path.\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/145580\u001b[39;00m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/frugal-notebooks-env/lib/python3.9/ctypes/__init__.py:382\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "# Load fine-tuned model\n",
    "fine_tuned_model = PeftModel.from_pretrained(model, \"fine_tuned_model\")\n",
    "fine_tuned_model = fine_tuned_model.merge_and_unload()  # For LoRA models\n",
    "\n",
    "# Inference\n",
    "y_pred, _ = batch_inference(model, tokenizer, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849e23d6-45e7-42b0-aaf7-4edcfb6c8ae7",
   "metadata": {},
   "source": [
    "### **Prediction function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc20f104-24b7-4f84-b1f7-472e3a7f9ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "def classify_text(text, tokenizer, model):\n",
    "    prompt = create_prompt(text)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    tracker = EmissionsTracker(log_level=\"error\")\n",
    "    tracker.start()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_new_tokens=2,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    inference_emissions = tracker.stop()\n",
    "    inference_time = tracker.final_emissions_data.duration\n",
    "    inference_energy_conso = tracker.final_emissions_data.energy_consumed\n",
    "\n",
    "    inf_efficiency_metrics_df = pd.DataFrame.from_dict([{\n",
    "        \"sample_latency_sec\": inference_time,\n",
    "        \"sample_energy_conso_kWh\": inference_energy_conso,\n",
    "        \"sample_emissions_kgCO2eq\": inference_emissions\n",
    "    }])\n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return response, inf_efficiency_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8c969db-06a8-4421-9506-9566c1e85f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(response):\n",
    "    prediction = response.split(\"Category number:\")[-1].strip()\n",
    "    prediction = ''.join(filter(str.isdigit, prediction))\n",
    "    \n",
    "    if prediction.isdigit() and int(prediction) in range(8):\n",
    "        return CLASS_LABELS[int(prediction)]\n",
    "    return \"error\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc532fc-f3cd-47cb-a77e-2785e96573c0",
   "metadata": {},
   "source": [
    "### **Testing on a single sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b658ecf-a35e-450e-8289-3dd40d904ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistralai/Mistral-7B-Instruct-v0.1'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44cf634a-efd7-4a7f-8744-fbfe7781299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model device: mps:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model device: {model.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c40df-eceb-4880-8e73-fbb088ed360b",
   "metadata": {},
   "source": [
    "**Sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79c16aee-26c7-469d-9805-7a13c2074ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is clear, compelling evidence that many of the major conclusions of the IPCC, your new religions constantly-changing Holy Book, are based on evidence that has been fabricated. The hockey stick graph that purported to abolish the mediaeval warm period is just one example.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = test_df['quote'][0]\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ae11d-a9e5-4e02-b329-ab30257891c3",
   "metadata": {},
   "source": [
    "**Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3828837-8e87-4ff0-b76e-f0d7ad1439fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "single_raw_prediction, single_metrics_df = classify_text(sample_text, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f184a578-86c4-47f7-86a4-31183c544bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote:\n",
      "There is clear, compelling evidence that many of the major conclusions of the IPCC, your new religions constantly-changing Holy Book, are based on evidence that has been fabricated. The hockey stick graph that purported to abolish the mediaeval warm period is just one example.\n",
      "\n",
      "Prediction: 6_proponents_biased\n",
      "True label: 5_science_unreliable\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_latency_sec</th>\n",
       "      <th>sample_energy_conso_kWh</th>\n",
       "      <th>sample_emissions_kgCO2eq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.973958</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_latency_sec  sample_energy_conso_kWh  sample_emissions_kgCO2eq\n",
       "0           10.973958                 0.000157                  0.000009"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print('Raw prediction:\\n\\n', single_raw_prediction)\n",
    "\n",
    "single_prediction = parse_output(single_raw_prediction)\n",
    "print(f'Quote:\\n{sample_text}')\n",
    "print(f'\\nPrediction: {single_prediction}')\n",
    "print(f\"True label: {df['label'][0]}\")\n",
    "print()\n",
    "single_metrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de4d4bc-fc72-434c-b43e-e8f13d57556a",
   "metadata": {},
   "source": [
    "### **Testing on a larger sample size**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac1e15c-61ad-4581-a54b-37c38ac3575c",
   "metadata": {},
   "source": [
    "##### **Sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35ab0ac7-cf45-4966-8b8c-899fb70e11ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mann could be said to be the Jerry Sandusky of climate science, except for instead of molesting children, he has molested and tortured data in the service of politicized science that could have dire economic consequences for the nation and planet,” Rand Simberg wrote in\\xa0National Review\\xa0article in\\xa02012.',\n",
       " 'The reality is that the infra-red active gases act more like an umbrella providing the Earths surface with shade to keep it cool than like a greenhouse to keep it warmer. It is a much more realistic description of the infra-red active gases to call them shade gases, rather than greenhouse gases.',\n",
       " '“Late 20th century and early 21st century global warming, they show, is neither dramatic, nor unusual, nor scary. Here … are just some of the charts to prove it.”',\n",
       " 'Our research has shown that the concentration of carbon dioxide in the atmosphere has no impact on global temperatures, or the climate.',\n",
       " 'I am speaking only as a layman who observes that there is plenty of snow in our winters these days, and who wonders whether it might be time for government to start taking seriously the possibility — however remote — that [Piers] Corbyn is right,']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "N_SAMPLES = 50\n",
    "\n",
    "df_test = test_df.sample(N_SAMPLES, random_state=42)\n",
    "X_test = df_test['quote'].tolist()\n",
    "y_test = df_test['label'].tolist()\n",
    "\n",
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b24865-0f18-4465-aa74-d38bb65a2fdd",
   "metadata": {},
   "source": [
    "##### **Inference function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c491599-1975-40a3-a08c-f134ca0b4165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_inference(model, tokenizer, X_test):\n",
    "    predictions = []\n",
    "    metrics_list = []\n",
    "    errors = 0\n",
    "    \n",
    "    for i, quote in enumerate(X_test):\n",
    "        print(f'Progress : quote {i}/{len(X_test)} | {round(i/len(X_test)*100, 2)}%')\n",
    "        try:\n",
    "            pred, metrics_df = classify_text(quote, tokenizer, model)\n",
    "            pred = parse_output(pred)\n",
    "            predictions.append(pred)\n",
    "            metrics_list.append(metrics_df.iloc[0])\n",
    "    \n",
    "            if pred == \"error\":\n",
    "                errors += 1\n",
    "        except Exception as e:\n",
    "            predictions.append(\"error\")\n",
    "            errors += 1\n",
    "            print(f\"Error processing: {text[:50]}... -> {str(e)}\")\n",
    "\n",
    "    if metrics_list:\n",
    "        batch_metrics_df = pd.DataFrame(metrics_list, columns=[\n",
    "            \"sample_latency_sec\",\n",
    "            \"sample_energy_conso_kWh\",\n",
    "            \"sample_emissions_kgCO2eq\"\n",
    "        ])\n",
    "        inf_efficiency_metrics = {\n",
    "            \"total_latency_sec\": np.sum(batch_metrics_df['sample_latency_sec']),\n",
    "            \"sample_latency_sec\": np.mean(batch_metrics_df['sample_latency_sec']),\n",
    "            \"total_energy_conso_kWh\": np.sum(batch_metrics_df['sample_energy_conso_kWh']),\n",
    "            \"sample_energy_conso_kWh\": np.mean(batch_metrics_df['sample_energy_conso_kWh']),\n",
    "            \"total_emissions_kgCO2eq\": np.sum(batch_metrics_df['sample_emissions_kgCO2eq'])\n",
    "        }\n",
    "    if errors:\n",
    "        print(f\"Total errors: {errors}\")\n",
    "\n",
    "    return predictions, inf_efficiency_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cbe048-c044-480a-946c-e41faa73d18a",
   "metadata": {},
   "source": [
    "##### **Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70580771-71b1-4535-8171-db721cff860c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistralai/Mistral-7B-Instruct-v0.1'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2a04387-1c30-4c95-82c0-751a983589ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<instruction>\\nClassify the following statement into one of these 8 categories:\\nRespond STRICTLY with only the corresponding number.\\n</instruction>\\n\\n<categories>\\n0 - Not relevant: No climate-related claims or doesn\\'t fit other categories\\n1 - Denial: Claims climate change is not happening\\n2 - Attribution denial: Claims human activity is not causing climate change\\n3 - Impact minimization: Claims climate change impacts are minimal or beneficial\\n4 - Solution opposition: Claims solutions to climate change are harmful\\n5 - Science skepticism: Challenges climate science validity or methods\\n6 - Actor criticism: Attacks credibility of climate scientists or activists\\n7 - Fossil fuel promotion: Asserts importance of fossil fuels\\n</categories>\\n\\n<statement>\\nStatement: \"\"\\n</statement>\\n\\nCategory number:'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_prompt('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77b2a43d-6f57-47b9-b1b5-ce37c935c9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset : 1133 char\n",
      "truncated dataset : 722 char\n",
      "X_test : original\n"
     ]
    }
   ],
   "source": [
    "print(\"original dataset :\", max([len(x) for x in df_test['quote'].tolist()]), 'char')\n",
    "print(\"truncated dataset :\", max([len(x) for x in df_test['truncated_quote'].tolist()]), 'char')\n",
    "print(\"X_test :\", 'original' if max([len(x) for x in X_test]) == 1133 else 'truncated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2233469-e685-4c2f-9ca8-cccc209c80b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated time to compute : 9 min 9 sec\n"
     ]
    }
   ],
   "source": [
    "est_time = single_metrics_df['sample_latency_sec'][0] * N_SAMPLES\n",
    "print(f\"Estimated time to compute : {round(est_time//60)} min {round(est_time%60)} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d3c97-380e-4ab2-b94e-b4923df812f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress : quote 0/50 | 0.0%\n",
      "Progress : quote 1/50 | 2.0%\n",
      "Progress : quote 2/50 | 4.0%\n",
      "Progress : quote 3/50 | 6.0%\n",
      "Progress : quote 4/50 | 8.0%\n",
      "Progress : quote 5/50 | 10.0%\n",
      "Progress : quote 6/50 | 12.0%\n",
      "Progress : quote 7/50 | 14.0%\n",
      "Progress : quote 8/50 | 16.0%\n",
      "Progress : quote 9/50 | 18.0%\n",
      "Progress : quote 10/50 | 20.0%\n",
      "Progress : quote 11/50 | 22.0%\n",
      "Progress : quote 12/50 | 24.0%\n",
      "Progress : quote 13/50 | 26.0%\n",
      "Progress : quote 14/50 | 28.0%\n",
      "Progress : quote 15/50 | 30.0%\n",
      "Progress : quote 16/50 | 32.0%\n",
      "Progress : quote 17/50 | 34.0%\n",
      "Progress : quote 18/50 | 36.0%\n"
     ]
    }
   ],
   "source": [
    "y_pred, efficiency_metrics_df = batch_inference(model, tokenizer, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05cd59-722c-4d39-af91-9e439eb80a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_time = efficiency_metrics_df['total_latency_sec']\n",
    "print(f\"Effective time to compute : {round(eff_time//60)} min {round(eff_time%60)} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ad7295-84ac-4383-893d-62727b3a9a40",
   "metadata": {},
   "source": [
    "**Efficiency Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9494bf03-3dca-4d45-8eb3-b24eb23ef227",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficiency_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936fe02c-e03a-438a-9cb5-348eeec199b5",
   "metadata": {},
   "source": [
    "**Performance Metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e021bf4-2534-4e82-a873-a0a8007de261",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc8d875-89b4-44fd-8556-0d490035e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def evaluation(X_test, y_test, y_pred):\n",
    "    # Store results in a DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test,\n",
    "        'y_pred': y_pred\n",
    "    })\n",
    "    results[\"correct\"] = results[\"y_test\"] == results[\"y_pred\"]\n",
    "\n",
    "    # Compute overall performance breakdown\n",
    "    correct = np.sum(results[\"correct\"])\n",
    "    errors = np.sum(results[\"y_pred\"] == 'error')\n",
    "    incorrect = len(results) - correct - errors\n",
    "    \n",
    "    performance = pd.DataFrame({\n",
    "        'Outcome': ['Correct', 'Incorrect', 'Error'],\n",
    "        'Count': [correct,incorrect,errors]\n",
    "        })\n",
    "\n",
    "    # Compute overall accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Get category labels (sorted for consistency)\n",
    "    category_names = sorted(pd.Series(y_test).unique())\n",
    "\n",
    "    # Compute per-class metrics\n",
    "    class_accuracy = results.groupby(\"y_test\")[\"correct\"].mean().reindex(category_names, fill_value=0).values\n",
    "    precision = precision_score(y_test, y_pred, average=None, labels=category_names, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average=None, labels=category_names, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average=None, labels=category_names, zero_division=0)\n",
    "\n",
    "    # Store per-category metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Category\": category_names,\n",
    "        \"Accuracy\": class_accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1\n",
    "    })\n",
    "\n",
    "    return results, accuracy, metrics_df, performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d7d3b-e0e6-43b8-995b-1935913063a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred):\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    labels = np.unique(y_test)  # Unique class labels\n",
    "    \n",
    "    # Compute TP, FP, FN, TN for each class\n",
    "    tp = np.diag(cm)  # True Positives (diagonal)\n",
    "    fp = cm.sum(axis=0) - tp  # Column sum minus TP\n",
    "    fn = cm.sum(axis=1) - tp  # Row sum minus TP\n",
    "    tn = cm.sum() - (tp + fp + fn)  # Total samples - (TP + FP + FN)\n",
    "    \n",
    "    print('Sample size:', N_SAMPLES)\n",
    "    print(f'True positives: \\t{tp.sum()}')\n",
    "    print(f'False positives:\\t{fp.sum()}')\n",
    "    print(f'False negatives:\\t{fn.sum()}')\n",
    "    \n",
    "    # 📊 3️⃣ **Plot Full Multi-Class Confusion Matrix**\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Full 8-Class Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0544a2-6bd3-4196-ae88-48c9160ba8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics(performance, metrics_df):\n",
    "    # Create side-by-side plots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Classification Performance Breakdown (Bar Chart)\n",
    "    axes[0].bar(performance['Outcome'], performance['Count'], color=['green', 'red', 'gray'])\n",
    "    axes[0].set_title(\"Classification Performance Breakdown\", fontsize=14)\n",
    "    axes[0].set_ylabel(\"Count\", fontsize=12)\n",
    "    axes[0].set_xlabel(\"Outcome\", fontsize=12)\n",
    "    \n",
    "    # Line Plot for F1 Score, Precision, Recall\n",
    "    categories = metrics_df['Category']\n",
    "    \n",
    "    axes[1].plot(categories, metrics_df['F1 Score'], marker='o', label='F1 Score')\n",
    "    axes[1].plot(categories, metrics_df['Precision'], marker='s', label='Precision')\n",
    "    axes[1].plot(categories, metrics_df['Recall'], marker='^', label='Recall')\n",
    "    \n",
    "    axes[1].axhline(y=accuracy, color='r', linestyle='--', label=f'Accuracy ({accuracy:.2f})')\n",
    "    \n",
    "    axes[1].set_xlabel(\"Category\", fontsize=12)\n",
    "    axes[1].set_ylabel(\"Score\", fontsize=12)\n",
    "    axes[1].set_title(\"Evaluation Metrics per Category\", fontsize=14)\n",
    "    axes[1].set_xticks(range(len(categories)))\n",
    "    axes[1].set_xticklabels(categories, rotation=45, ha=\"right\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Adjust layout and show\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d367fc-39f9-488e-950b-fff7170b959d",
   "metadata": {},
   "source": [
    "##### **Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3db16-ebb7-4586-a814-a6bba443b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df, accuracy, metrics_df, performance = evaluation(X_test, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a30a4d-538a-418c-8aa6-003fc49acc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022fa4c-8aeb-452a-9521-680b16d91138",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31a0b23-836e-4299-9e54-fe357602a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy: {accuracy}\\n')\n",
    "\n",
    "metrics_df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76573abb-f38d-498a-98cc-c30764617f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(performance, metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be30b1-a801-4e36-9d83-69e5a812295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.concat([\n",
    "    results_df['y_test'].value_counts().sort_index(),\n",
    "    results_df['y_pred'].value_counts().sort_index()\n",
    "], axis=1)\n",
    "r.columns = ['y_test', 'y_pred']\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c58df88-c846-428c-9b8b-b63945b48593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79109e95-7ab5-4696-9197-87137ac9e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd36a70-e4a7-48f6-a5d1-5b3d5e1f4093",
   "metadata": {},
   "source": [
    "## **Let's save the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8277ac-0688-4f0e-bf9c-092c55cfbb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9932a72d-a9a6-488b-a627-92ee16693323",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = (\n",
    "    \"metrics/\"\n",
    "    f\"{'_'.join(model_name.split('/'))}\"\n",
    "    f\"_accuracy_{int(accuracy * 100)}\"\n",
    "    f\"_dt_{timestamp.replace(':', '').replace('-', '')}\"\n",
    "    \".json\"\n",
    ")\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d36b1e-6000-49db-97fe-96abe94a961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "note = \"Baseline SLM, step by step, quote cropping\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80425ac-a12a-4fd4-94f9-501b79acaa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajouter category metrics\n",
    "\n",
    "os.makedirs(\"metrics\", exist_ok=True)\n",
    "\n",
    "data = {\n",
    "    \"model_name\": model_name,\n",
    "    \"timestamp\": timestamp,\n",
    "    \"note\": note,\n",
    "    \"test_size\" : N_SAMPLES,\n",
    "    \"quote_max_len\": (max([len(x) for x in X_test])),\n",
    "    \"test_accuracy\": accuracy,\n",
    "\n",
    "    \"total_latency_sec\": efficiency_metrics_df['total_latency_sec'],\n",
    "    \"total_energy_conso_kWh\": efficiency_metrics_df['total_energy_conso_kWh'],\n",
    "\n",
    "    \"sample_latency_sec\": efficiency_metrics_df['sample_latency_sec'],\n",
    "    \"sample_energy_conso_kWh\": efficiency_metrics_df['sample_energy_conso_kWh'],\n",
    "    \"total_emissions_kgCO2eq\": efficiency_metrics_df['total_emissions_kgCO2eq'],\n",
    "\n",
    "    \"class_performance_metrics\": metrics_df.to_dict(orient=\"records\"),\n",
    "    \"prompt\": create_prompt('')\n",
    "}\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e129b-7d2c-4697-b44f-d09018db350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(filename, \"w\") as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "print(f\"Metrics saved to {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
